{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#dataset : Amazon fine food reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Source : https://www.kaggle.com/laowingkin/amazon-fine-food-review-sentiment-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from string import punctuation\n",
    "from sklearn import svm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "#from itertools import chain\n",
    "#from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df = pd.read_csv('/home/shiv/Dataset/Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " y_dict = {1:0, 2:0, 4:1, 5:1}\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame({'score':[1,2,3,4,5], 'uid': [12,23,45,56,43]})\n",
    "temp_score=  df1['score'].map(y_dict)\n",
    "df1.score = temp_score\n",
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing nuetral reviews, with value 3 \n",
    "#df = df[df['Score'] != 3]\n",
    "\n",
    "#mapping score with poistive and negative\n",
    "\n",
    "def partition(x):\n",
    "    if x < 3:\n",
    "        return '1'\n",
    "    return '0'\n",
    "\n",
    "temp_score = df.Score\n",
    "ts = temp_score.map(partition)\n",
    "df.Score = ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
       "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df['Text']\n",
    "y = df.Score\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    I have bought several of the Vitality canned d...\n",
       "1    Product arrived labeled as Jumbo Salted Peanut...\n",
       "2    This is a confection that has been around a fe...\n",
       "3    If you are looking for the secret ingredient i...\n",
       "4    Great taffy at a great price.  There was a wid...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression model on word count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shiv/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.9234347073476223\n",
      "\n",
      "-Top 20 positive-\n",
      "         Word  Coefficient\n",
      "  undrinkable     2.936746\n",
      "       ripoff     2.815729\n",
      "    deceptive     2.696162\n",
      "  disapointed     2.678524\n",
      "        worst     2.407214\n",
      "        lousy     2.405120\n",
      "        blech     2.368444\n",
      "         lame     2.353332\n",
      "   unbearable     2.346018\n",
      "        ruins     2.244851\n",
      "      weakest     2.241170\n",
      "  embarrassed     2.218491\n",
      "      vomited     2.202253\n",
      "         vile     2.187482\n",
      "        schar     2.179580\n",
      "   returnable     2.165382\n",
      "      defeats     2.106338\n",
      " unacceptable     2.105772\n",
      "          ick     2.081416\n",
      "     vinegary     2.071368\n",
      "\n",
      "-Top 20 negative-\n",
      "         Word  Coefficient\n",
      "     terrific    -1.668224\n",
      " unmistakable    -1.690465\n",
      "      easiest    -1.716821\n",
      "        steal    -1.730062\n",
      "      gobbles    -1.746297\n",
      "    amazingly    -1.750267\n",
      "       brings    -1.769412\n",
      "      trainer    -1.797404\n",
      "      drained    -1.847494\n",
      "      worries    -1.849322\n",
      " conventional    -1.959105\n",
      "     drawback    -1.966748\n",
      "       delish    -2.043792\n",
      "     soothing    -2.132844\n",
      "       resist    -2.148430\n",
      "       hooked    -2.244220\n",
      "    skeptical    -2.353791\n",
      "    addicting    -2.584897\n",
      "   pleasantly    -2.890360\n",
      "     downside    -3.067710\n"
     ]
    }
   ],
   "source": [
    "c = CountVectorizer(stop_words = 'english')\n",
    "\n",
    "def text_fit(X, y, model,clf_model,coef_show=1):\n",
    "    \n",
    "    X_c = model.fit_transform(X)\n",
    "    #print('# features: {}'.format(X_c.shape[1]))\n",
    "    #split into train and test \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_c, y, random_state=0)\n",
    "   # print('# train records: {}'.format(X_train.shape[0]))\n",
    "    #print('# test records: {}'.format(X_test.shape[0]))\n",
    "    clf = clf_model.fit(X_train, y_train)\n",
    "    acc = clf.score(X_test, y_test)\n",
    "    print ('Model Accuracy: {}'.format(acc))\n",
    "    \n",
    "    if coef_show == 1: \n",
    "        w = model.get_feature_names()\n",
    "        coef = clf.coef_.tolist()[0]\n",
    "        coeff_df = pd.DataFrame({'Word' : w, 'Coefficient' : coef})\n",
    "        coeff_df = coeff_df.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\n",
    "        print('')\n",
    "        print('-Top 20 positive-')\n",
    "        print(coeff_df.head(20).to_string(index=False))\n",
    "        print('')\n",
    "        print('-Top 20 negative-')        \n",
    "        print(coeff_df.tail(20).to_string(index=False))\n",
    "    \n",
    "    \n",
    "text_fit(X, y, c, LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression model on TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shiv/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.9224284729161096\n",
      "\n",
      "-Top 20 positive-\n",
      "           Word  Coefficient\n",
      "          worst    10.376925\n",
      "       terrible     8.594575\n",
      "          awful     8.197440\n",
      "  disappointing     7.696216\n",
      "       horrible     7.340680\n",
      "   disappointed     6.832412\n",
      " disappointment     6.764436\n",
      "          threw     6.514545\n",
      "     disgusting     6.297724\n",
      "      tasteless     6.268056\n",
      "           yuck     6.084551\n",
      "    undrinkable     6.029501\n",
      "          waste     5.801447\n",
      "           poor     5.662441\n",
      "         return     5.592851\n",
      "          gross     5.563182\n",
      "          nasty     5.479702\n",
      "  unfortunately     5.315167\n",
      "        useless     5.251654\n",
      "          worse     5.023765\n",
      "\n",
      "-Top 20 negative-\n",
      "       Word  Coefficient\n",
      "       easy    -5.522381\n",
      "       beat    -5.544556\n",
      "      yummy    -5.821393\n",
      "  fantastic    -5.851143\n",
      "   favorite    -6.183643\n",
      "    awesome    -6.245762\n",
      " pleasantly    -6.317389\n",
      "    amazing    -6.417974\n",
      "       nice    -6.509099\n",
      "       good    -6.584429\n",
      "  wonderful    -6.808270\n",
      "     hooked    -6.980448\n",
      "       love    -7.580867\n",
      "     highly    -7.841608\n",
      "  excellent    -8.406027\n",
      "      loves    -8.790851\n",
      "    perfect    -9.368310\n",
      "       best   -10.147444\n",
      "  delicious   -10.551248\n",
      "      great   -11.940290\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words = 'english')\n",
    "text_fit(X, y, tfidf, LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression model on TFIDF + ngram¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_n = TfidfVectorizer(ngram_range=(1,2),stop_words = 'english')\n",
    "text_fit(X, y, tfidf_n, LogisticRegression())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
